<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Welcome to My Homepage" href="http://yoursite.com/rss.xml"><link rel="alternate" type="application/atom+xml" title="Welcome to My Homepage" href="http://yoursite.com/atom.xml"><link rel="alternate" type="application/json" title="Welcome to My Homepage" href="http://yoursite.com/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="Research,Tongji"><link rel="canonical" href="http://yoursite.com/academic/research/tongji/url/"><title>Unsupervised Reinforcement Learning for Multi task Autonomous Driving - Tongji - Research - Academic | I'm Zhenyu Ma = Welcome to My Homepage = Now, I'm working on my PhD application.</title><meta name="generator" content="Hexo 5.4.2"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Unsupervised Reinforcement Learning for Multi task Autonomous Driving</h1><div class="meta"><span class="item" title="Created: 2023-08-01 09:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">Posted on</span> <time itemprop="dateCreated datePublished" datetime="2023-08-01T09:00:00+08:00">2023-08-01</time> </span><span class="item" title="Symbols count in article"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">Symbols count in article</span> <span>5.3k</span> <span class="text">words</span> </span><span class="item" title="Reading time"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">Reading time</span> <span>5 mins.</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">I'm Zhenyu Ma</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><img src="https://s2.loli.net/2024/02/02/BaGVTDPnYLq3re8.png"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">Home</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/academic/" itemprop="item" rel="index" title="In Academic"><span itemprop="name">Academic</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/academic/research/" itemprop="item" rel="index" title="In Research"><span itemprop="name">Research</span></a><meta itemprop="position" content="2"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/academic/research/tongji/" itemprop="item" rel="index" title="In Tongji"><span itemprop="name">Tongji</span></a><meta itemprop="position" content="3"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="en"><link itemprop="mainEntityOfPage" href="http://yoursite.com/academic/research/tongji/url/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/bio.jpg"><meta itemprop="name" content="Zhenyu Ma"><meta itemprop="description" content="Now, I'm working on my PhD application., I am a graduate student specializing in AI and AGI, currently applying for a Ph.D. program."></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Welcome to My Homepage"></span><div class="body md" itemprop="articleBody"><div class="note info"><p><strong>title:</strong> Unsupervised Reinforcement Learning for Multi-task Autonomous Driving: Expanding Skills and Cultivating Curiosity</p></div><div class="note info"><p><strong>abstract:</strong> In recent years, reinforcement learning (RL) has been widely used in decision-making. However, it still faces challenges when it is applied to autonomous driving, especially in complex multi-task scenarios. This paper introduces an unsupervised reinforcement learning(URL), called an improved Contrastive Intrinsic Control (CIC), to address this problem. CIC generates skills as transferable factors between different tasks to enable multi-task expansion. By comparing skills as potential state transfers with real state transfers, the mutual information between the two serves as the curiosity that drives the agents to explore the environment and gather experience in advance. This helps the collection of valuable experiences and the acquisition of effective skills. In the multi-task expansion phase, the unified training skills are used as a prior to enabling rapid convergence in various environments. Unified training is performed without rewards, followed by repeated training on multiple downstream tasks. Experiments are conducted in a highway environment, where three different driving modes are differentiated as separate RL tasks through reward functions. The experimental results demonstrate that the proposed method possesses the ability of multi-task learning. Compared to the Deep Deterministic Policy Gradient (DDPG) baseline, it achieves a 30% to 50% improvement in convergence speed at the single-task level and a 20% to 40% improvement in the final learning performance. Furthermore, even in complex tasks, where other RL methods struggle to learn effectively, it still achieves an obvious learning ability. This approach realizes an effective combination of curiosity mechanism, and RL decision making in the multitasking domain.</p></div><div class="note primary"><p>This paper has been published in IEEE Transactions on <span class="exturl" data-url="aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2Fic3RyYWN0L2RvY3VtZW50LzEwNTM4MjIx">Intelligent Transportation Systems (IEEE T-ITS)</span>, and we welcome your citations!</p></div><h3 id="introduction"><a class="anchor" href="#introduction">#</a> Introduction</h3><p>As the first author of the paper &quot;Unsupervised Reinforcement Learning for Multi-task Autonomous Driving: Expanding Skills and Cultivating Curiosity,&quot; I am pleased to present a summary and technical report of our research. This study addresses the challenges of applying reinforcement learning (RL) to autonomous driving, especially in complex multi-task scenarios. We introduce an improved Contrastive Intrinsic Control (CIC) method to enhance skill transfer between different tasks, thereby enabling effective multi-task expansion and improving the performance of autonomous driving systems.</p><p><img data-src="https://s2.loli.net/2024/06/14/HcuNCthM7kGboKg.jpg" alt="cic"></p><h3 id="background"><a class="anchor" href="#background">#</a> Background</h3><p>Reinforcement learning has been extensively used for decision-making in autonomous driving. However, traditional RL methods face significant challenges in multi-task environments due to their inability to differentiate common factors among tasks and to learn multiple tasks simultaneously. Existing approaches often require complex structures or compromise between different optimization criteria, making them less effective for practical autonomous driving applications.</p><h3 id="proposed-method"><a class="anchor" href="#proposed-method">#</a> Proposed Method</h3><p>Our method leverages the improved CIC algorithm, which utilizes unsupervised reinforcement learning (URL) to generate transferable skills as meta-information between different tasks. By comparing potential state transfers (skills) with actual state transfers, the mutual information serves as a curiosity driver, encouraging the agent to explore the environment and gather valuable experience. This process helps in the acquisition of effective skills and enables rapid convergence in various environments.</p><p>The key components of our method include:</p><ol><li><strong>Skill Generation and Transfer</strong>: Skills are generated as potential state transfers and used to drive the agent's exploration.</li><li><strong>Mutual Information as Curiosity Driver</strong>: Mutual information between potential and actual state transfers is used to motivate the agent's exploration.</li><li><strong>Unified Training for Multi-task Expansion</strong>: Skills are used as prior knowledge for multi-task expansion, allowing for rapid adaptation and convergence in different tasks.</li></ol><p><img data-src="https://s2.loli.net/2024/06/14/s9rLfBTU7ywjI8c.jpg" alt="cic"></p><h3 id="experimental-design"><a class="anchor" href="#experimental-design">#</a> Experimental Design</h3><p>We conducted experiments in a simulated highway environment, differentiating three driving modes (tasks) through reward functions: speed mode, energy-saving mode, and safety mode. These tasks were designed to represent distinct driving behaviors and objectives.</p><h3 id="results-and-analysis"><a class="anchor" href="#results-and-analysis">#</a> Results and Analysis</h3><p>Our experimental results demonstrate the effectiveness of the improved CIC method in multi-task autonomous driving:</p><ol><li><strong>Convergence Speed</strong>: The CIC method achieved a 30% to 50% improvement in convergence speed compared to the Deep Deterministic Policy Gradient (DDPG) baseline at the single-task level.</li><li><strong>Learning Performance</strong>: There was a 20% to 40% improvement in the final learning performance across different tasks.</li><li><strong>Robustness in Complex Tasks</strong>: The CIC method showed a strong learning ability even in complex tasks where other RL methods struggled to learn effectively.</li></ol><h3 id="conclusion"><a class="anchor" href="#conclusion">#</a> Conclusion</h3><p>This study introduces a novel approach to unsupervised reinforcement learning for multi-task autonomous driving. By leveraging the improved CIC method, we achieve significant improvements in skill transfer, exploration efficiency, and overall learning performance. Our method effectively combines curiosity mechanisms with RL decision-making, making it well-suited for the dynamic and uncertain environments encountered in autonomous driving.</p><h3 id="future-work"><a class="anchor" href="#future-work">#</a> Future Work</h3><p>Future research will focus on extending this approach to other domains and exploring additional strategies to enhance the robustness and adaptability of RL agents in complex environments. We aim to further improve the efficiency of skill generation and transfer processes, as well as to optimize the integration of curiosity-driven exploration with RL decision-making.</p><p>This technical report provides an overview of our research, highlighting the key contributions and experimental findings, and demonstrates the potential of unsupervised reinforcement learning for advancing multi-task autonomous driving systems.</p><div class="tags"><a href="/tags/research/" rel="tag"><i class="ic i-tag"></i> Research</a> <a href="/tags/Tongji/" rel="tag"><i class="ic i-tag"></i> Tongji</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">Edited on</span> <time title="Modified: 2024-06-14 23:24:12" itemprop="dateModified" datetime="2024-06-14T23:24:12+08:00">2024-06-14</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> Donate</button><p>Give me a cup of [coffee]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="Zhenyu Ma WeChat Pay"><p>WeChat Pay</p></div><div><img data-src="/images/alipay.png" alt="Zhenyu Ma Alipay"><p>Alipay</p></div><div><img data-src="/images/paypal.png" alt="Zhenyu Ma PayPal"><p>PayPal</p></div></div></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>Zhenyu Ma <i class="ic i-at"><em>@</em></i>Welcome to My Homepage</li><li class="link"><strong>Post link: </strong><a href="http://yoursite.com/academic/research/tongji/url/" title="Unsupervised Reinforcement Learning for Multi task Autonomous Driving">http://yoursite.com/academic/research/tongji/url/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/academic/engineer/tongji/nk/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;06&#x2F;15&#x2F;AhyY2s78qmdiGTZ.png" title="Self-Evolving Learning-Based Autonomous Driving System"><span class="type">Previous Post</span> <span class="category"><i class="ic i-flag"></i> Tongji</span><h3>Self-Evolving Learning-Based Autonomous Driving System</h3></a></div><div class="item right"><a href="/academic/research/tongji/ssc/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;02&#x2F;02&#x2F;HUKizj8yEW9nmbc.jpg" title="Siamese Network-Driven Unsupervised RL"><span class="type">Next Post</span> <span class="category"><i class="ic i-flag"></i> Tongji</span><h3>Siamese Network-Driven Unsupervised RL</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#background"><span class="toc-number">2.</span> <span class="toc-text">Background</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#proposed-method"><span class="toc-number">3.</span> <span class="toc-text">Proposed Method</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#experimental-design"><span class="toc-number">4.</span> <span class="toc-text">Experimental Design</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#results-and-analysis"><span class="toc-number">5.</span> <span class="toc-text">Results and Analysis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#conclusion"><span class="toc-number">6.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#future-work"><span class="toc-number">7.</span> <span class="toc-text">Future Work</span></a></li></ol></div><div class="related panel pjax" data-title="Related"><ul><li class="active"><a href="/academic/research/tongji/url/" rel="bookmark" title="Unsupervised Reinforcement Learning for Multi task Autonomous Driving">Unsupervised Reinforcement Learning for Multi task Autonomous Driving</a></li><li><a href="/academic/research/tongji/ssc/" rel="bookmark" title="Siamese Network-Driven Unsupervised RL">Siamese Network-Driven Unsupervised RL</a></li><li><a href="/academic/research/tongji/config/" rel="bookmark" title="Unsupervised RL to Continual RL">Unsupervised RL to Continual RL</a></li><li><a href="/academic/research/tongji/simmt/" rel="bookmark" title="Simplified Meta-Transfer  to Improve  Exploration of Reinforcement Learning">Simplified Meta-Transfer to Improve Exploration of Reinforcement Learning</a></li></ul></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Zhenyu Ma" data-src="/images/bio.jpg"><p class="name" itemprop="name">Zhenyu Ma</p><div class="description" itemprop="description">I am a graduate student specializing in AI and AGI, currently applying for a Ph.D. program.</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">10</span> <span class="name">posts</span></a></div><div class="item categories"><a href="/categories/"><span class="count">8</span> <span class="name">categories</span></a></div><div class="item tags"><a href="/tags/"><span class="count">6</span> <span class="name">tags</span></a></div></nav><div class="social"><span class="exturl item google" data-url="aHR0cHM6Ly9zY2hvbGFyLmdvb2dsZS5jb20vY2l0YXRpb25zP3VzZXI9M0pyQ1JrOEFBQUFKJmhsPXpoLUNO" title="https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?user&#x3D;3JrCRk8AAAAJ&amp;hl&#x3D;zh-CN"><i class="ic i-chrome"></i></span> <a href="/mazy0403@outlook.com" title="mazy0403@outlook.com" class="item email"><i class="ic i-envelope"></i></a> <span class="exturl item linkedin" data-url="aHR0cHM6Ly93d3cubGlua2VkaW4uY29tL2luL3poZW55dS1tYS0zMTM1NzMyYjYv" title="https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;zhenyu-ma-3135732b6&#x2F;"><i class="ic i-link-alt"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9tdS15aW5nLXNoYW4tODc=" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;mu-ying-shan-87"><i class="ic i-zhihu"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly91emx3MC1qM3Nhei5weXhsLmFpLw==" title="https:&#x2F;&#x2F;uzlw0-j3saz.pyxl.ai&#x2F;"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>Posts</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>Archives</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>Categories</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>Tags</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>Friends</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/academic/engineer/tongji/nk/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/academic/research/tongji/ssc/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/shanghaiqizhi/" title="In Shanghai Qi Zhi">Shanghai Qi Zhi</a></div><span><a href="/academic/research/shanghaiqizhi/dex/" title="Shanghai Qi Zhi, Robot Motion Planning">Shanghai Qi Zhi, Robot Motion Planning</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/tongji/" title="In Tongji">Tongji</a></div><span><a href="/academic/research/tongji/simmt/" title="Simplified Meta-Transfer  to Improve  Exploration of Reinforcement Learning">Simplified Meta-Transfer to Improve Exploration of Reinforcement Learning</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/engineer/" title="In Engineer">Engineer</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/engineer/tongji/" title="In Tongji">Tongji</a></div><span><a href="/academic/engineer/tongji/nfsc/" title="Adaptive Evolution and Evaluation of Secure and Confident Intelligent Systems.">Adaptive Evolution and Evaluation of Secure and Confident Intelligent Systems.</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/engineer/" title="In Engineer">Engineer</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/engineer/jlu/" title="In JLU">JLU</a></div><span><a href="/academic/engineer/jlu/machine/" title="I, and JLU Racing, Jilin University.">I, and JLU Racing, Jilin University.</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/tongji/" title="In Tongji">Tongji</a></div><span><a href="/academic/research/tongji/ssc/" title="Siamese Network-Driven Unsupervised RL">Siamese Network-Driven Unsupervised RL</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/engineer/" title="In Engineer">Engineer</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/engineer/tongji/" title="In Tongji">Tongji</a></div><span><a href="/academic/engineer/tongji/nk/" title="Self-Evolving Learning-Based Autonomous Driving System">Self-Evolving Learning-Based Autonomous Driving System</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/tongji/" title="In Tongji">Tongji</a></div><span><a href="/academic/research/tongji/config/" title="Unsupervised RL to Continual RL">Unsupervised RL to Continual RL</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/tongji/" title="In Tongji">Tongji</a></div><span><a href="/academic/research/tongji/url/" title="Unsupervised Reinforcement Learning for Multi task Autonomous Driving">Unsupervised Reinforcement Learning for Multi task Autonomous Driving</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/jlu/" title="In JLU">JLU</a></div><span><a href="/academic/research/jlu/machine/" title="Mechanical Design at JLU Racing, Jilin University.">Mechanical Design at JLU Racing, Jilin University.</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a></div><span><a href="/academic/research/research/" title="I am applying for a PhD, and this is my CV.">I am applying for a PhD, and this is my CV.</a></span></li></ul></div><div><h2>Recent Comments</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Zhenyu Ma @ I'm Zhenyu Ma</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="Symbols count total">44k words</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="Reading time total">40 mins.</span></div><div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"academic/research/tongji/url/",favicon:{show:"（●´3｀●）Goooood",hide:"(´Д｀)Booooom"},search:{placeholder:"Search for Posts",empty:"We didn't find any results for the search: ${query}",stats:"${hits} results found in ${time} ms"},valine:{placeholder:""},fancybox:!0,copyright:'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>