<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="Welcome to My Homepage" href="http://yoursite.com/rss.xml"><link rel="alternate" type="application/atom+xml" title="Welcome to My Homepage" href="http://yoursite.com/atom.xml"><link rel="alternate" type="application/json" title="Welcome to My Homepage" href="http://yoursite.com/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="Research,Tongji"><link rel="canonical" href="http://yoursite.com/academic/research/tongji/simmt/"><title>Simplified Meta-Transfer to Improve Exploration of Reinforcement Learning - Tongji - Research - Academic | I'm Zhenyu Ma = Welcome to My Homepage = Now, I'm working on my PhD application.</title><meta name="generator" content="Hexo 5.4.2"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Simplified Meta-Transfer to Improve Exploration of Reinforcement Learning</h1><div class="meta"><span class="item" title="Created: 2024-05-19 09:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">Posted on</span> <time itemprop="dateCreated datePublished" datetime="2024-05-19T09:00:00+08:00">2024-05-19</time> </span><span class="item" title="Symbols count in article"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">Symbols count in article</span> <span>4.2k</span> <span class="text">words</span> </span><span class="item" title="Reading time"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">Reading time</span> <span>4 mins.</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">I'm Zhenyu Ma</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><img src="https://s2.loli.net/2024/02/02/qL8ZngRJXNUicjQ.png"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">Home</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/academic/" itemprop="item" rel="index" title="In Academic"><span itemprop="name">Academic</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/academic/research/" itemprop="item" rel="index" title="In Research"><span itemprop="name">Research</span></a><meta itemprop="position" content="2"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/academic/research/tongji/" itemprop="item" rel="index" title="In Tongji"><span itemprop="name">Tongji</span></a><meta itemprop="position" content="3"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="en"><link itemprop="mainEntityOfPage" href="http://yoursite.com/academic/research/tongji/simmt/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/bio.jpg"><meta itemprop="name" content="Zhenyu Ma"><meta itemprop="description" content="Now, I'm working on my PhD application., I am a graduate student specializing in AI and AGI, currently applying for a Ph.D. program."></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Welcome to My Homepage"></span><div class="body md" itemprop="articleBody"><div class="note info"><p><strong>title:</strong> Simplified Meta-Transfer to Improve Exploration of Reinforcement Learning</p></div><div class="note info"><p><strong>abstract:</strong> Reinforcement learning (RL) agents are suffering from the reward sparsity in complex environments, especially for autonomous driving caused by corner scenarios and uncertain conditions. The reason is that complex environments feature the presence of severe reward hackings and mixed sparse rewards. In this paper, we propose a Simplified Meta-Transfer (SimMT) method, which uses two floating-point numbers as conservative and aggressive exploration factors and constructs meta-transfer information, respectively. The states are further augmented separately and competence-based unsupervised reinforcement learning (URL) with further compensation for intrinsic motivation drives the agents to explore the environment. The proposed method is analyzed under various traffic flow conditions, and the effect is improved by more than 45% compared to the baseline. Currently SimMT realizes SOTA in the field of RL for autonomous driving decision making.</p></div><h3 id="introduction"><a class="anchor" href="#introduction">#</a> Introduction</h3><p>I am the first author of the paper &quot;Simplified Meta-Transfer to Improve Exploration of Reinforcement Learning.&quot; In this study, we investigate the challenges faced by reinforcement learning (RL) agents in complex environments, particularly in autonomous driving, where sparse rewards are caused by corner scenarios and uncertain conditions. To address these issues, we propose the Simplified Meta-Transfer (SimMT) method, which uses two floating-point numbers as conservative and aggressive exploration factors to construct meta-transfer information. This method further augments states and uses competence-based unsupervised reinforcement learning (URL) to drive agents to explore the environment.</p><h3 id="background"><a class="anchor" href="#background">#</a> Background</h3><p>Exploration and curiosity methods have been effective in dealing with sparse rewards in RL environments. However, the complexity of autonomous driving environments exceeds the capabilities of these methods. While existing methods provide partial solutions, there is no mature RL method that can fully address the complexities of traffic environments. Our SimMT method aims to enhance exploration in these challenging conditions.</p><p><img data-src="https://s2.loli.net/2024/02/02/RplvHdJbWMCQy13.png" alt="sim"></p><h3 id="methodology"><a class="anchor" href="#methodology">#</a> Methodology</h3><p>Our approach leverages the competence-based URL framework and introduces compensatory intrinsic motivation to drive agents' exploration. SimMT employs mutually exclusive perspectives to discover different policies by maximizing their mutual information, implicitly expressing the exploration drive and deterministic policy discovery process. Unlike other competence-based URL methods, SimMT does not involve complex skill transfer and only requires two floating-point numbers to complete the process.</p><h3 id="experimental-design"><a class="anchor" href="#experimental-design">#</a> Experimental Design</h3><p>We tested our proposed method in various traffic flow conditions, using a highway environment to simulate different traffic densities and lane configurations. The agent is designed as a self-driving vehicle capable of perceiving its surroundings and making decisions based on throttle depth and steering angle signals.</p><p><img data-src="https://s2.loli.net/2024/02/02/qL8ZngRJXNUicjQ.png" alt="sim"></p><h3 id="results-and-analysis"><a class="anchor" href="#results-and-analysis">#</a> Results and Analysis</h3><p>Our experimental results demonstrate that SimMT improves performance by over 45% compared to baseline methods in complex environments. SimMT consistently outperforms other methods across multiple traffic flow scenarios, maintaining leading and stable results.</p><ol><li>SimMT combines comparison schemes and compensatory motivation to optimize the exploration process, achieving closer approximations to policy goals.</li><li>By avoiding the noise effects of skill transfer, SimMT maximizes the efficiency of information transfer using two floating-point numbers as experience transfers.</li><li>SimMT consistently leads in performance across various traffic flow environments.</li></ol><h3 id="conclusion"><a class="anchor" href="#conclusion">#</a> Conclusion</h3><p>This study focuses on transitioning RL decisions from simple to complex environments that more closely resemble real-world scenarios. SimMT is designed to enhance exploration by addressing the sensitivity and effectiveness of methods in complex environments. We conclude that:</p><ol><li>The innovative τ(1)i and τ(2)j structures effectively address the sensitivity of exploration methods to the environment.</li><li>Compensatory motivation provides sufficient exploration in complex environments.</li><li>SimMT demonstrates superior performance and stability across various experimental settings.</li></ol><p><img data-src="https://s2.loli.net/2024/02/02/8CMvWK6cxUnGFoJ.png" alt="sim"></p><h3 id="future-work"><a class="anchor" href="#future-work">#</a> Future Work</h3><p>Future research will extend this method to additional domains and explore strategies to further mitigate sparse reward issues in complex environments. We aim to develop continuous learning capabilities for urban traffic flow environments.</p><p>This technical report summarizes our research, covering the background, methodology, experimental design, results, and conclusions, demonstrating the effectiveness of the SimMT method in complex RL environments.</p><div class="tags"><a href="/tags/research/" rel="tag"><i class="ic i-tag"></i> Research</a> <a href="/tags/Tongji/" rel="tag"><i class="ic i-tag"></i> Tongji</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">Edited on</span> <time title="Modified: 2024-06-14 23:24:53" itemprop="dateModified" datetime="2024-06-14T23:24:53+08:00">2024-06-14</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> Donate</button><p>Give me a cup of [coffee]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="Zhenyu Ma WeChat Pay"><p>WeChat Pay</p></div><div><img data-src="/images/alipay.png" alt="Zhenyu Ma Alipay"><p>Alipay</p></div><div><img data-src="/images/paypal.png" alt="Zhenyu Ma PayPal"><p>PayPal</p></div></div></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>Zhenyu Ma <i class="ic i-at"><em>@</em></i>Welcome to My Homepage</li><li class="link"><strong>Post link: </strong><a href="http://yoursite.com/academic/research/tongji/simmt/" title="Simplified Meta-Transfer  to Improve  Exploration of Reinforcement Learning">http://yoursite.com/academic/research/tongji/simmt/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/academic/research/tongji/config/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;02&#x2F;02&#x2F;Hkrj9mat6McdWS7.png" title="Unsupervised RL to Continual RL"><span class="type">Previous Post</span> <span class="category"><i class="ic i-flag"></i> Tongji</span><h3>Unsupervised RL to Continual RL</h3></a></div><div class="item right"><a href="/academic/research/research/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2024&#x2F;06&#x2F;14&#x2F;BbeAITaJNSE4PKV.jpg" title="I am applying for a PhD, and this is my CV."><span class="type">Next Post</span> <span class="category"><i class="ic i-flag"></i> Research</span><h3>I am applying for a PhD, and this is my CV.</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#background"><span class="toc-number">2.</span> <span class="toc-text">Background</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#methodology"><span class="toc-number">3.</span> <span class="toc-text">Methodology</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#experimental-design"><span class="toc-number">4.</span> <span class="toc-text">Experimental Design</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#results-and-analysis"><span class="toc-number">5.</span> <span class="toc-text">Results and Analysis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#conclusion"><span class="toc-number">6.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#future-work"><span class="toc-number">7.</span> <span class="toc-text">Future Work</span></a></li></ol></div><div class="related panel pjax" data-title="Related"><ul><li><a href="/academic/research/tongji/url/" rel="bookmark" title="Unsupervised Reinforcement Learning for Multi task Autonomous Driving">Unsupervised Reinforcement Learning for Multi task Autonomous Driving</a></li><li><a href="/academic/research/tongji/ssc/" rel="bookmark" title="Siamese Network-Driven Unsupervised RL">Siamese Network-Driven Unsupervised RL</a></li><li><a href="/academic/research/tongji/config/" rel="bookmark" title="Unsupervised RL to Continual RL">Unsupervised RL to Continual RL</a></li><li class="active"><a href="/academic/research/tongji/simmt/" rel="bookmark" title="Simplified Meta-Transfer  to Improve  Exploration of Reinforcement Learning">Simplified Meta-Transfer to Improve Exploration of Reinforcement Learning</a></li></ul></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Zhenyu Ma" data-src="/images/bio.jpg"><p class="name" itemprop="name">Zhenyu Ma</p><div class="description" itemprop="description">I am a graduate student specializing in AI and AGI, currently applying for a Ph.D. program.</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">10</span> <span class="name">posts</span></a></div><div class="item categories"><a href="/categories/"><span class="count">8</span> <span class="name">categories</span></a></div><div class="item tags"><a href="/tags/"><span class="count">6</span> <span class="name">tags</span></a></div></nav><div class="social"><span class="exturl item google" data-url="aHR0cHM6Ly9zY2hvbGFyLmdvb2dsZS5jb20vY2l0YXRpb25zP3VzZXI9M0pyQ1JrOEFBQUFKJmhsPXpoLUNO" title="https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?user&#x3D;3JrCRk8AAAAJ&amp;hl&#x3D;zh-CN"><i class="ic i-chrome"></i></span> <a href="/mazy0403@outlook.com" title="mazy0403@outlook.com" class="item email"><i class="ic i-envelope"></i></a> <span class="exturl item linkedin" data-url="aHR0cHM6Ly93d3cubGlua2VkaW4uY29tL2luL3poZW55dS1tYS0zMTM1NzMyYjYv" title="https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;zhenyu-ma-3135732b6&#x2F;"><i class="ic i-link-alt"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9tdS15aW5nLXNoYW4tODc=" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;mu-ying-shan-87"><i class="ic i-zhihu"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly91emx3MC1qM3Nhei5weXhsLmFpLw==" title="https:&#x2F;&#x2F;uzlw0-j3saz.pyxl.ai&#x2F;"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>Posts</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>Archives</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>Categories</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>Tags</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>Friends</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/academic/research/tongji/config/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/academic/research/research/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/shanghaiqizhi/" title="In Shanghai Qi Zhi">Shanghai Qi Zhi</a></div><span><a href="/academic/research/shanghaiqizhi/dex/" title="Shanghai Qi Zhi, Robot Motion Planning">Shanghai Qi Zhi, Robot Motion Planning</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a></div><span><a href="/academic/research/research/" title="I am applying for a PhD, and this is my CV.">I am applying for a PhD, and this is my CV.</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/engineer/" title="In Engineer">Engineer</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/engineer/tongji/" title="In Tongji">Tongji</a></div><span><a href="/academic/engineer/tongji/nk/" title="Self-Evolving Learning-Based Autonomous Driving System">Self-Evolving Learning-Based Autonomous Driving System</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/jlu/" title="In JLU">JLU</a></div><span><a href="/academic/research/jlu/machine/" title="Mechanical Design at JLU Racing, Jilin University.">Mechanical Design at JLU Racing, Jilin University.</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/engineer/" title="In Engineer">Engineer</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/engineer/tongji/" title="In Tongji">Tongji</a></div><span><a href="/academic/engineer/tongji/nfsc/" title="Adaptive Evolution and Evaluation of Secure and Confident Intelligent Systems.">Adaptive Evolution and Evaluation of Secure and Confident Intelligent Systems.</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/tongji/" title="In Tongji">Tongji</a></div><span><a href="/academic/research/tongji/ssc/" title="Siamese Network-Driven Unsupervised RL">Siamese Network-Driven Unsupervised RL</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/tongji/" title="In Tongji">Tongji</a></div><span><a href="/academic/research/tongji/url/" title="Unsupervised Reinforcement Learning for Multi task Autonomous Driving">Unsupervised Reinforcement Learning for Multi task Autonomous Driving</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/tongji/" title="In Tongji">Tongji</a></div><span><a href="/academic/research/tongji/simmt/" title="Simplified Meta-Transfer  to Improve  Exploration of Reinforcement Learning">Simplified Meta-Transfer to Improve Exploration of Reinforcement Learning</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/" title="In Research">Research</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/research/tongji/" title="In Tongji">Tongji</a></div><span><a href="/academic/research/tongji/config/" title="Unsupervised RL to Continual RL">Unsupervised RL to Continual RL</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/academic/" title="In Academic">Academic</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/engineer/" title="In Engineer">Engineer</a> <i class="ic i-angle-right"></i> <a href="/categories/academic/engineer/jlu/" title="In JLU">JLU</a></div><span><a href="/academic/engineer/jlu/machine/" title="I, and JLU Racing, Jilin University.">I, and JLU Racing, Jilin University.</a></span></li></ul></div><div><h2>Recent Comments</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Zhenyu Ma @ I'm Zhenyu Ma</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="Symbols count total">44k words</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="Reading time total">40 mins.</span></div><div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"academic/research/tongji/simmt/",favicon:{show:"（●´3｀●）Goooood",hide:"(´Д｀)Booooom"},search:{placeholder:"Search for Posts",empty:"We didn't find any results for the search: ${query}",stats:"${hits} results found in ${time} ms"},valine:{placeholder:""},fancybox:!0,copyright:'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>