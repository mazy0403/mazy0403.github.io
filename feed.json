{
    "version": "https://jsonfeed.org/version/1",
    "title": "Welcome to My Homepage",
    "subtitle": "Now, I'm working on my PhD application.",
    "icon": "http://yoursite.com/images/favicon.ico",
    "description": "I am a graduate student specializing in AI and AGI, currently applying for a Ph.D. program.",
    "home_page_url": "http://yoursite.com",
    "items": [
        {
            "id": "http://yoursite.com/academic/research/research/",
            "url": "http://yoursite.com/academic/research/research/",
            "title": "I am applying for a PhD, and this is my CV.",
            "date_published": "2024-05-31T16:00:00.000Z",
            "content_html": "<div class=\"note info\">\n<p>I am currently applying for a PhD, and my research interests are primarily focused on AI and AGI technologies. My main research areas include autonomous driving and robotics, with a primary focus on decision-making and motion planning. I am particularly interested in reinforcement learning methods, with an emphasis on enhancing diversity and task information inference. Below is my resume:</p>\n</div>\n<p><strong>Zhenyu Ma</strong></p>\n<p>+86 13331705980 | E-mail: <span class=\"exturl\" data-url=\"bWFpbHRvOm1henkwNDAzQG91dGxvb2suY29t\">mazy0403@outlook.com</span></p>\n<p>HomePage: <span class=\"exturl\" data-url=\"aHR0cDovL21henkwNDAzLmdpdGh1Yi5pbw==\">mazy0403.github.io</span> | LinkedIn: zhenyu-ma-3135732b6</p>\n<h1 id=\"education\"><a class=\"anchor\" href=\"#education\">#</a> EDUCATION</h1>\n<h3 id=\"tsinghua-university-shanghai-qi-zhi-institute\"><a class=\"anchor\" href=\"#tsinghua-university-shanghai-qi-zhi-institute\">#</a> Tsinghua University &amp; Shanghai Qi Zhi Institute</h3>\n<p>Mar 2024 - Dec 2024</p>\n<p><em><strong>Internship in Embodied AI &amp; Robotic Project</strong></em></p>\n<ul>\n<li>\n<p>Research Interests: Embodied AI and Robotic Motion Planning, Especially Dexterous Hands.</p>\n</li>\n<li>\n<p>Advisior: A/Prof. Jianyu Chen (Department of Cross-Information, Tsinghua University).</p>\n</li>\n</ul>\n<h3 id=\"tongji-university\"><a class=\"anchor\" href=\"#tongji-university\">#</a> Tongji University</h3>\n<p>Sep 2022 - Mar 2025</p>\n<p><em><strong>Master's degree in Vehicle Engineering Master</strong></em></p>\n<ul>\n<li>\n<p>Research Interests: Decision-making for Autonomous Vehicles, Expecially RL Method.</p>\n</li>\n<li>\n<p>Advisor: Prof. Yanjun Huang.</p>\n</li>\n</ul>\n<h3 id=\"jilin-university\"><a class=\"anchor\" href=\"#jilin-university\">#</a> Jilin University</h3>\n<p>Aug 2018 - Jul 2022</p>\n<ul>\n<li>Bachelor's degree in Vehicle Engineering</li>\n</ul>\n<h1 id=\"publications\"><a class=\"anchor\" href=\"#publications\">#</a> PUBLICATIONS</h1>\n<h3 id=\"tongji-university-the-school-of-automotive-studies-yanjun-huangs-group\"><a class=\"anchor\" href=\"#tongji-university-the-school-of-automotive-studies-yanjun-huangs-group\">#</a> Tongji University (the School of Automotive Studies, Yanjun Huang's Group)</h3>\n<p>May 2023 - Present</p>\n<ul>\n<li>\n<p>[1] <strong>Z. Ma</strong>, X. Liu and Y. Huang, &quot;Unsupervised Reinforcement Learning for Multi-Task Autonomous Driving: Expanding Skills and Cultivating Curiosity,&quot; in IEEE Transactions on Intelligent Transportation Systems, doi: 10.1109/TITS.2024.3400224.</p>\n</li>\n<li>\n<p>[2] <strong>Z. Ma</strong> and Y. Huang, &quot;A Lightweight Siamese Network-Driven Unsupervised Reinforcement Learning&quot;, in IEEE Robotics and Automation Letters, 2023. <strong>(under review)</strong></p>\n</li>\n<li>\n<p>[3] <strong>Z. Ma</strong>, Y. Rong and Y. Huang, &quot;Simplified Meta Transfer Enhancing Reinforcement Learning Exploratio&quot;, in Neural Information Processing Systems, 2024. <strong>(under review)</strong></p>\n</li>\n<li>\n<p>[4] <strong>Z. Ma</strong>, Y. Cui and Y. Huang, &quot;from Unsupervised Reinforcement Learning to Continual Reinforcement Learning: Leading Learning from the Relevance to the Whole of Autonomous Driving&quot;, in IEEE International Conference on Intelligent Transportation Systems, 2024. <strong>(under review)</strong></p>\n</li>\n<li>\n<p>[5] S. Yang, C. Wang, <strong>Z. Ma</strong>, P. Li, Y. Huang, H. Chen, &quot;A Safety-Oriented Self-Learning Algorithm for Autonomous Driving: Evolution Starting from a Basic Model&quot;, in IEEE Transactions on Industrial Electronics, 2024. <strong>(under review)</strong></p>\n</li>\n<li>\n<p>[6] Y. Rong, <strong>Z. Ma</strong>, Y. Huang, &quot;A Unified Information Encoding Framework for Autonomous Driving: Multi-Task and Multi-Scenario Decision-Making Using a General Encoder&quot;, in arXiv.</p>\n</li>\n</ul>\n<h3 id=\"jilin-university-jlu-racing-baja-team\"><a class=\"anchor\" href=\"#jilin-university-jlu-racing-baja-team\">#</a> JiLin University (JLU Racing, BAJA Team)</h3>\n<p>Nov 2018 - May 2022</p>\n<ul>\n<li>[7] Z. Jin, R. Shan, D. Wang, Q. Sun, <strong>Z. Ma</strong> and M. Li, Characterization of a rubber-belted CVT in a Baja-based race car, in Journal of Mechanical Transmission 46.1 (2022): 143-147.</li>\n<li>[8] Z. Jin, M. Li, Z. Wang, D. Wa, <strong>Z. Ma</strong>, R. Shan, G. Zhang, X. Liu and P. Li, Design of a time-shared four-wheel drive transmission system for a BAJA racing vehicle, in &quot;2020 Proceedings of the Annual Conference of the China SAE&quot;.</li>\n</ul>\n<h1 id=\"patent\"><a class=\"anchor\" href=\"#patent\">#</a> PATENT</h1>\n<ul>\n<li>[1] D. Wang, <strong>Z. Ma</strong>, Z. Jin, Q.Sun, Z. Yin, Z. Luo, Q. Wang and W. Jin, &quot;A kind of main gearbox for full-time four-wheel-drive small all-terrain vehicles&quot;, CN113007317A / CN214661881U, CN202110421653.7 / CN202120803224.1.</li>\n<li>[2] D. Wang, Q.Sun, Z. Jin, <strong>Z. Ma</strong>, Z. Yin, Q. Wang, Z. Luo and W. Jin, &quot;A full-time four-wheel drive transmission system for small all-terrain off-road vehicles&quot;, CN112937291A / CN214647574U, CN202110463640.6/ CN202120871787.4.</li>\n<li>[3] Z. Jin, <strong>Z. Ma</strong>, Q. Sun, R. Shan, X. Liu, G. Zhang, P. Li, M. Li, X. Li and Z. Wang, &quot;A shift mechanism and reducer for BAJA racing cars&quot;, CN112145633A / CN213981861U, CN202011158793.1 / CN202022403477.8.</li>\n<li>[4] Z. Jin, M. Li, X. Li, Z. Wang, <strong>Z. Ma</strong>, Y. Shan, G. Zhang, P. Li and X. Liu&quot;A kind of 4WD reducer housing and reducer for BAJA racing cars&quot;, CN111963654A / CN212564321U, CN202010875292.9 / CN202021817867.3.</li>\n</ul>\n<h1 id=\"research-experience\"><a class=\"anchor\" href=\"#research-experience\">#</a> RESEARCH EXPERIENCE</h1>\n<h3 id=\"embodied-agi-groups-shanghai-qi-zhi-institute-department-of-cross-information-tsinghua-university-directed-by-aprof-jianyu-chen\"><a class=\"anchor\" href=\"#embodied-agi-groups-shanghai-qi-zhi-institute-department-of-cross-information-tsinghua-university-directed-by-aprof-jianyu-chen\">#</a> Embodied AGI Groups | Shanghai Qi Zhi Institute &amp; Department of Cross-Information, Tsinghua University | Directed by A/Prof. Jianyu Chen.</h3>\n<p>Mar 2024 - Present</p>\n<ul>\n<li>Interning at the embodied AGI project team of Shanghai Qi Zhi Institute and Department of Cross-Information, Tsinghua University, supervised by Assistant Professor Jianyu Chen.</li>\n<li>Focusing on motion planning for long-term tasks of dexterous hands, such as tool usage of dexterous hands.</li>\n</ul>\n<h3 id=\"self-evolving-learning-based-autonomous-driving-system-tongji-university-directed-by-prof-yanjun-huang-no2022yfb2502900-supported-by-national-key-research-and-development-program-the-highest-level-of-rd-programme-in-china\"><a class=\"anchor\" href=\"#self-evolving-learning-based-autonomous-driving-system-tongji-university-directed-by-prof-yanjun-huang-no2022yfb2502900-supported-by-national-key-research-and-development-program-the-highest-level-of-rd-programme-in-china\">#</a> Self-Evolving Learning-Based Autonomous Driving System | Tongji University | Directed by Prof. Yanjun Huang | (No2022YFB2502900) | Supported by National Key Research and Development Program (the highest level of R&amp;D programme in China).</h3>\n<p>Aug 2022 - Present</p>\n<ul>\n<li>Developed an improved unsupervised RL framework for autonomous driving. Leading to significant improvements in decision-making and learning speed about 30% and 40%.</li>\n<li>Focused on multi-vehicle cooperative evolution. Leading a major project within the national key R&amp;D program.</li>\n<li>Participating in the construction of mixed reality simulation test platform by combining vehicle hardware-in-the-loop and virtual traffic scenarios. And currently developing a general simulation software.</li>\n<li>Participating in the design of a generalized autonomous driving observation encoder that can utilize LiDAR observation information to effectively improve reinforcement learning decision-making.</li>\n</ul>\n<h3 id=\"adaptive-evolution-and-evaluation-of-secure-and-confident-intelligent-systems-decision-of-autonomous-driving-algorithms-in-complex-environments-tongji-university-directed-by-prof-yanjun-huang-u23b2061-supported-by-the-national-natural-science-foundation-of-china-nsfc\"><a class=\"anchor\" href=\"#adaptive-evolution-and-evaluation-of-secure-and-confident-intelligent-systems-decision-of-autonomous-driving-algorithms-in-complex-environments-tongji-university-directed-by-prof-yanjun-huang-u23b2061-supported-by-the-national-natural-science-foundation-of-china-nsfc\">#</a> Adaptive Evolution and Evaluation of Secure and Confident Intelligent Systems: Decision of Autonomous Driving  Algorithms in Complex Environments | Tongji University | Directed by Prof. Yanjun Huang | (U23B2061) | Supported by the National Natural Science Foundation of China (NSFC).</h3>\n<p>Oct 2023 - Present</p>\n<ul>\n<li>Developed a leading RL algorithm in the field of autonomous driving, <strong>Simplified Meta-Transfer</strong> (SimMT), utilizing efficient exploration architecture. Currently under review at NIPS. Compared with DDPG baseline, decision-making level is improved by 45%. Realizing leading of the RL in the field of autonomous driving decision-making.</li>\n<li>Developed an improved <strong>Siamese similarity control</strong> (SSC) algorithm that significantly enhances convergence speed and learning efficiency.  Compared with the SOTA algorithm Contrastive Intrinsic Control (CIC), it is 30% lighter, doubles the pre-training speed, and improves the training efficiency of downstream tasks of bipedal robots by 5%~10%.</li>\n<li>Further exploring the potential of current unsupervised RL methods in continual learning of dynamic environments.</li>\n</ul>\n<h3 id=\"jlu-raing-team-leader-technical-director\"><a class=\"anchor\" href=\"#jlu-raing-team-leader-technical-director\">#</a> JLU Raing  （Team Leader, Technical Director）</h3>\n<p>Nov 2018 - May 2022</p>\n<ul>\n<li>The designer of the first part time four-wheel drive small sized all-terrain vehicle's transmission system in China.</li>\n<li>The designer of the first full time four-wheel-drive small sized all-terrain vehicle in China.</li>\n</ul>\n<h1 id=\"skills\"><a class=\"anchor\" href=\"#skills\">#</a> SKILLS</h1>\n<p><strong>Languages Skills:</strong> English, German, Chinese</p>\n<p><strong>Software Skills:</strong> Carla; Catia; Hypermish; Romax</p>\n<p>​     *Taught Catia courses at Jilin University.</p>\n<p>​     *Conducted corporate training on ROMAX for companies such as Fangzhenxiu.</p>\n<p><strong>Development Tools:</strong> Gym; Pytorch; Tensorflow;</p>\n<p><strong>Programming:</strong> Python; C++;</p>\n<p><strong>Engineering:</strong> Mechanical Design; Mechanical Process</p>\n<p>​     *Been invited to lecture on the mechanical design of race cars at institutions such as Changchun Automobile College.</p>\n<h1 id=\"honors-awards\"><a class=\"anchor\" href=\"#honors-awards\">#</a> HONORS &amp; AWARDS</h1>\n<p><strong>As the Principal Lead:</strong></p>\n<ul>\n<li>2018-2019 Season: China SAE BAJA competition Excellence Award <strong>(7/200+)</strong>.</li>\n<li>2020-2021 Season: China SAE BAJA competition First Prize, Design Champion <strong>(1/200+)</strong>.</li>\n<li>2021-2022 Season: China SAE BAJA competition First Prize, Design Champion <strong>(1/200+)</strong>.</li>\n</ul>\n<p><strong>As a participant:</strong></p>\n<ul>\n<li>\n<p>2018-2019 Season: China SAE Formula competition Design Champion <strong>(1/200+)</strong>,  Cost and Marketing Champion <strong>(1/200+)</strong>.</p>\n</li>\n<li>\n<p>2019-2020 Season: China SAE Formula competition Overall Champion <strong>(1/200+)</strong>, Virtual Race Champion <strong>(1/200+)</strong>.</p>\n</li>\n<li>\n<p>2020-2021 Season: China SAE Formula competition Overall Champion <strong>(1/200+)</strong>, Design Champion <strong>(1/200+)</strong>, Cost and Marketing Champion <strong>(1/200+)</strong>, China SAE Electric Formula competition Overall Champion <strong>(1/100+)</strong>.</p>\n</li>\n<li>\n<p>2021-2022 Season: China SAE Formula competition Overall Champion <strong>(1/200+)</strong>, Design Champion <strong>(1/200+)</strong>, Dynamic Events Champion <strong>(1/200+)</strong>.</p>\n</li>\n</ul>\n<h1 id=\"academic-services-mentorship\"><a class=\"anchor\" href=\"#academic-services-mentorship\">#</a> ACADEMIC SERVICES &amp; MENTORSHIP</h1>\n<p><strong>Reviewers</strong></p>\n<ul>\n<li>Part D: Journal of Automobile Engineering. (Nov 2023 - Present)</li>\n<li>IEEE Transactions on Intelligent Transportation Systems. (Mar 2024 - Present)</li>\n</ul>\n<p><strong>Mentoring</strong></p>\n<ul>\n<li>Shanghang Zhou (PhD)  Design of Multi-Vehicle Cooperative Self-Evolution Algorithms.  (Mar 2024 - Present)</li>\n<li>Xinyi Liu (MS)  Application of Unsupervised RL Algorithms in Autonomous Driving Decision-Making. (Dec 2022 - Jun 2023)</li>\n<li>Yu Rong (BS)  A Generalizable Visual Observation Encoder for Reinforcement Learning. (Jan 2023 - Present)</li>\n<li>Yixin Cui (BS)  Building a Continual RL Architecture Based on Unsupervised RL Algorithms. (Dec 2023 - Jun 2024)</li>\n</ul>\n<h1 id=\"leadership\"><a class=\"anchor\" href=\"#leadership\">#</a> LEADERSHIP</h1>\n<ul>\n<li><strong>Student leader</strong> of the sub-project &quot;Mixed Real Vehicle Validation of Learning-Based Autonomous Driving Systems&quot; within the National Key R&amp;D Program &quot;Self-Evolving Learning-Based Autonomous Driving System.&quot;</li>\n<li>In this project, my team includes members from Tsinghua University, Tongji University, Dongfeng Motor Corporation.</li>\n<li><strong>Captain and Technical Director</strong> of JLU Racing, BAJA during the 2019-2020 and 2020-2021 seasons.</li>\n<li><strong>Chief Judge</strong> of the 2022-2023 China SAE BAJA competition.</li>\n<li>Class Representative for the Chinese-German Program at Tongji University.</li>\n</ul>\n",
            "tags": [
                "Academic",
                "Research",
                "Research",
                "CV"
            ]
        },
        {
            "id": "http://yoursite.com/academic/research/tongji/simmt/",
            "url": "http://yoursite.com/academic/research/tongji/simmt/",
            "title": "Simplified Meta-Transfer  to Improve  Exploration of Reinforcement Learning",
            "date_published": "2024-05-19T01:00:00.000Z",
            "content_html": "<div class=\"note info\">\n<p><strong>title:</strong> Simplified Meta-Transfer to Improve  Exploration of Reinforcement Learning</p>\n</div>\n<div class=\"note info\">\n<p><strong>abstract:</strong> Reinforcement learning (RL) agents are suffering from the reward sparsity in complex environments, especially for autonomous driving caused by corner scenarios and uncertain conditions. The reason is that complex environments feature the presence of severe reward hackings and mixed sparse rewards.  In this paper, we propose a Simplified Meta-Transfer (SimMT) method, which uses two floating-point numbers as conservative and aggressive exploration factors and constructs meta-transfer information, respectively.  The states are further augmented separately and competence-based unsupervised reinforcement learning (URL) with further compensation for intrinsic motivation drives the agents to explore the environment.  The proposed method is analyzed under various traffic flow conditions, and the effect is improved by more than 45% compared to the baseline. Currently SimMT realizes SOTA in the field of RL for autonomous driving decision making.</p>\n</div>\n<h3 id=\"introduction\"><a class=\"anchor\" href=\"#introduction\">#</a> Introduction</h3>\n<p>I am the first author of the paper &quot;Simplified Meta-Transfer to Improve Exploration of Reinforcement Learning.&quot; In this study, we investigate the challenges faced by reinforcement learning (RL) agents in complex environments, particularly in autonomous driving, where sparse rewards are caused by corner scenarios and uncertain conditions. To address these issues, we propose the Simplified Meta-Transfer (SimMT) method, which uses two floating-point numbers as conservative and aggressive exploration factors to construct meta-transfer information. This method further augments states and uses competence-based unsupervised reinforcement learning (URL) to drive agents to explore the environment.</p>\n<h3 id=\"background\"><a class=\"anchor\" href=\"#background\">#</a> Background</h3>\n<p>Exploration and curiosity methods have been effective in dealing with sparse rewards in RL environments. However, the complexity of autonomous driving environments exceeds the capabilities of these methods. While existing methods provide partial solutions, there is no mature RL method that can fully address the complexities of traffic environments. Our SimMT method aims to enhance exploration in these challenging conditions.</p>\n<p><img data-src=\"https://s2.loli.net/2024/02/02/RplvHdJbWMCQy13.png\" alt=\"sim\" /></p>\n<h3 id=\"methodology\"><a class=\"anchor\" href=\"#methodology\">#</a> Methodology</h3>\n<p>Our approach leverages the competence-based URL framework and introduces compensatory intrinsic motivation to drive agents' exploration. SimMT employs mutually exclusive perspectives to discover different policies by maximizing their mutual information, implicitly expressing the exploration drive and deterministic policy discovery process. Unlike other competence-based URL methods, SimMT does not involve complex skill transfer and only requires two floating-point numbers to complete the process.</p>\n<h3 id=\"experimental-design\"><a class=\"anchor\" href=\"#experimental-design\">#</a> Experimental Design</h3>\n<p>We tested our proposed method in various traffic flow conditions, using a highway environment to simulate different traffic densities and lane configurations. The agent is designed as a self-driving vehicle capable of perceiving its surroundings and making decisions based on throttle depth and steering angle signals.</p>\n<p><img data-src=\"https://s2.loli.net/2024/02/02/qL8ZngRJXNUicjQ.png\" alt=\"sim\" /></p>\n<h3 id=\"results-and-analysis\"><a class=\"anchor\" href=\"#results-and-analysis\">#</a> Results and Analysis</h3>\n<p>Our experimental results demonstrate that SimMT improves performance by over 45% compared to baseline methods in complex environments. SimMT consistently outperforms other methods across multiple traffic flow scenarios, maintaining leading and stable results.</p>\n<ol>\n<li>SimMT combines comparison schemes and compensatory motivation to optimize the exploration process, achieving closer approximations to policy goals.</li>\n<li>By avoiding the noise effects of skill transfer, SimMT maximizes the efficiency of information transfer using two floating-point numbers as experience transfers.</li>\n<li>SimMT consistently leads in performance across various traffic flow environments.</li>\n</ol>\n<h3 id=\"conclusion\"><a class=\"anchor\" href=\"#conclusion\">#</a> Conclusion</h3>\n<p>This study focuses on transitioning RL decisions from simple to complex environments that more closely resemble real-world scenarios. SimMT is designed to enhance exploration by addressing the sensitivity and effectiveness of methods in complex environments. We conclude that:</p>\n<ol>\n<li>The innovative τ(1)i and τ(2)j structures effectively address the sensitivity of exploration methods to the environment.</li>\n<li>Compensatory motivation provides sufficient exploration in complex environments.</li>\n<li>SimMT demonstrates superior performance and stability across various experimental settings.</li>\n</ol>\n<p><img data-src=\"https://s2.loli.net/2024/02/02/8CMvWK6cxUnGFoJ.png\" alt=\"sim\" /></p>\n<h3 id=\"future-work\"><a class=\"anchor\" href=\"#future-work\">#</a> Future Work</h3>\n<p>Future research will extend this method to additional domains and explore strategies to further mitigate sparse reward issues in complex environments. We aim to develop continuous learning capabilities for urban traffic flow environments.</p>\n<p>This technical report summarizes our research, covering the background, methodology, experimental design, results, and conclusions, demonstrating the effectiveness of the SimMT method in complex RL environments.</p>\n",
            "tags": [
                "Academic",
                "Research",
                "Tongji",
                "Research",
                "Tongji"
            ]
        },
        {
            "id": "http://yoursite.com/academic/research/tongji/config/",
            "url": "http://yoursite.com/academic/research/tongji/config/",
            "title": "Unsupervised RL to Continual RL",
            "date_published": "2024-04-19T01:00:00.000Z",
            "content_html": "<div class=\"note info\">\n<p><strong>title:</strong> Unsupervised Reinforcement Learning to Continual Reinforcement Learning: from Relevance to Whole</p>\n</div>\n<div class=\"note info\">\n<p><strong>abstract:</strong> The lifelong learning process in human beings involves both the process of crossing between different domains and the process of changing environmental conditions. Among reinforcement learning(RL) methods, existing continuous learning approaches tend to be effective in dealing with learning across domains, while it is difficult to achieve results in the face of changing environments. This paper demonstrates and explains in detail a new idea to solve this kind of problem: using competence-based unsupervised reinforcement learning(URL) methods to learn invariant feature, relevance, of continuously changing environments. A continuous learning framework is also constructed based on the invariant relevance. By equipping the competency-based URL framework, this study successfully enables the RL baseline to acquire the ability to make decisions in changing environments, and improves the decision-making effect by 40% compared to the baseline.</p>\n</div>\n<h3 id=\"introduction\"><a class=\"anchor\" href=\"#introduction\">#</a> Introduction</h3>\n<p>As the first author of the paper &quot;From Unsupervised Reinforcement Learning to Continual Reinforcement Learning: Leading Learning from the Relevance to the Whole of Autonomous Driving Decision-Making,&quot; I am delighted to summarize our research and findings. This study addresses the challenges of autonomous driving decision-making in dynamically changing environments through a novel approach that leverages competence-based unsupervised reinforcement learning (RL) to identify correlations between different policies under real-time varying conditions.</p>\n<h3 id=\"problem-statement\"><a class=\"anchor\" href=\"#problem-statement\">#</a> Problem Statement</h3>\n<p>Reinforcement learning (RL) has proven to be a robust decision-making framework for autonomous driving, especially in stationary conditions. However, real-world scenarios are predominantly non-stationary, requiring vehicles to adapt to diverse and dynamic environmental conditions. Traditional RL methodologies assume environmental stationarity, which becomes inefficient when domain shifts occur. Continual RL approaches, on the other hand, embrace domain transitions, learning to adapt from one set of conditions to another, thereby addressing the challenges associated with domain adaptation in the autonomous driving sector.</p>\n<p><img data-src=\"https://s2.loli.net/2024/02/02/2FRbswEfC5npQhB.png\" alt=\"url\" /></p>\n<h3 id=\"proposed-approach\"><a class=\"anchor\" href=\"#proposed-approach\">#</a> Proposed Approach</h3>\n<p>We introduce a lifelong learning paradigm for autonomous driving that begins with competence-based unsupervised RL to identify relevance knowledge across different domains. This knowledge forms the foundation for continual learning, facilitating adaptation to continuously changing environments. Our approach utilizes contrastive learning and mutual information estimation to discover reusable latent state transitions, which are essential for constructing a lifelong learning architecture.</p>\n<h3 id=\"theoretical-foundation\"><a class=\"anchor\" href=\"#theoretical-foundation\">#</a> Theoretical Foundation</h3>\n<p>Our methodology is grounded in the Markov decision process (MDP) framework, incorporating potential state transfer information (denoted as z) discovered through the unsupervised RL algorithm. This approach maximizes mutual information to identify relevant knowledge across domains, ensuring that as learning progresses, the relevance between z and relevant information increases while diminishing its association with irrelevant information.</p>\n<h3 id=\"experimental-design\"><a class=\"anchor\" href=\"#experimental-design\">#</a> Experimental Design</h3>\n<p>To validate our approach, we conducted experiments in a variable-parameter autonomous driving environment, specifically a highway scenario with changing traffic densities. The experimental baselines included DDPG and other continual learning paradigms based on knowledge discovery algorithms such as Random Network Distillation (RND) and Active Pretraining with Successor Features (APS). The performance of these algorithms was compared against the competence-based URL algorithm (CIC).</p>\n<p><img data-src=\"https://s2.loli.net/2024/02/03/zWjUNsa59gT1AqD.png\" alt=\"ch\" /></p>\n<h3 id=\"results-and-analysis\"><a class=\"anchor\" href=\"#results-and-analysis\">#</a> Results and Analysis</h3>\n<p>Our experimental results demonstrated significant improvements in the continual learning paradigm based on the CIC algorithm compared to traditional RL baselines. The CIC algorithm achieved superior performance in environments with regularly and randomly varying traffic densities. Additionally, the continual learning paradigm constructed from the CIC algorithm outperformed the original CIC algorithm in a stationary environment, highlighting the importance of rich exploration experiences in dynamic environments.</p>\n<h3 id=\"conclusion\"><a class=\"anchor\" href=\"#conclusion\">#</a> Conclusion</h3>\n<p>This study establishes a continual learning paradigm for autonomous driving using competence-based unsupervised RL. Our approach effectively adapts to changing conditions, leveraging relevance discovery to construct a lifelong learning architecture. The findings suggest that continuously changing environments can enhance the diversity of exploration experiences, further improving learning outcomes.</p>\n<h3 id=\"future-work\"><a class=\"anchor\" href=\"#future-work\">#</a> Future Work</h3>\n<p>Future research will focus on extending this methodology to other domains and exploring additional strategies for mitigating forgetting in continual learning. We aim to refine our approach to achieve even greater adaptability and robustness in autonomous driving decision-making.</p>\n<h3 id=\"references\"><a class=\"anchor\" href=\"#references\">#</a> References</h3>\n<p>The references section of the original paper provides detailed citations of the studies and methodologies that informed our research.</p>\n<p>This technical report encapsulates the core contributions and findings of our paper, emphasizing the novel approach and its implications for autonomous driving in dynamically changing environments.</p>\n",
            "tags": [
                "Academic",
                "Research",
                "Tongji",
                "Research",
                "Tongji"
            ]
        },
        {
            "id": "http://yoursite.com/academic/research/shanghaiqizhi/dex/",
            "url": "http://yoursite.com/academic/research/shanghaiqizhi/dex/",
            "title": "Shanghai Qi Zhi, Robot Motion Planning",
            "date_published": "2024-03-19T01:00:00.000Z",
            "content_html": "<p>I am currently interning at the Institute for Interdisciplinary Information Sciences (IIIS) at Tsinghua University and the Shanghai Qi Zhi Institute. My advisor is Assistant Professor Jianyu Chen from the IIIS at Tsinghua University. Our research group is dedicated to studying embodied AGI. My research focuses on solving motion planning problems for dexterous hands in complex, long-term tasks.</p>\n",
            "tags": [
                "Academic",
                "Research",
                "Shanghai Qi Zhi",
                "Research",
                "Shanghai Qi Zhi"
            ]
        },
        {
            "id": "http://yoursite.com/academic/engineer/tongji/nfsc/",
            "url": "http://yoursite.com/academic/engineer/tongji/nfsc/",
            "title": "Adaptive Evolution and Evaluation of Secure and Confident Intelligent Systems.",
            "date_published": "2024-01-19T01:00:00.000Z",
            "content_html": "<div class=\"note info\">\n<p><strong>project:</strong> Adaptive Evolution and Evaluation of Secure and Confident Intelligent Systems.</p>\n</div>\n<div class=\"note info\">\n<p><strong>introduction:</strong> The &quot;Adaptive Evolution and Evaluation of Secure and Confident Intelligent Systems.&quot; project addresses critical challenges in the realm of autonomous driving, focusing on enhancing safety, robustness, efficiency, and transparency of perception and decision-making systems.</p>\n<p>In the dynamic and complex environments that autonomous vehicles navigate, precise and reliable perception and decision-making are paramount. The project aims to overcome the current limitations of weak safety, poor adaptability, low learning efficiency, and lack of transparency in intelligent systems by leveraging human cognitive and domain knowledge. This is achieved through data-driven and mechanistic collaboration methods, which enhance the efficacy, robustness, safety, and interpretability of autonomous driving systems.</p>\n<p>Key research areas include human-augmented perception methods, mechanistic knowledge-enhanced autonomous decision-making methods, and explainable perception and decision-making algorithms. The project also emphasizes the creation of a closed-loop automated learning framework for training, testing, and evaluating these algorithms.</p>\n</div>\n<p><strong>Self-Evolving Learning-Based Autonomous Driving System | Tongji University | Directed by Prof. Yanjun Huang | (No2022YFB2502900) | Supported by National Key Research and Development Program (the highest level of R&amp;D programme in China).</strong></p>\n<p>I have developed a pioneering reinforcement learning (RL) algorithm in the field of autonomous driving, known as Simplified Meta-Transfer (SimMT). This algorithm utilizes an efficient exploration architecture, significantly enhancing decision-making capabilities. The SimMT algorithm is currently under review at NIPS. Through rigorous testing and comparison, it has been demonstrated that SimMT improves decision-making levels by 45% compared to the Deep Deterministic Policy Gradient (DDPG) baseline. This achievement underscores our leadership in applying RL to autonomous driving decision-making.</p>\n<p>In addition, I have developed an improved Siamese Similarity Control (SSC) algorithm, which significantly boosts convergence speed and learning efficiency. This new algorithm is 30% lighter and doubles the pre-training speed compared to the state-of-the-art algorithm, Contrastive Intrinsic Control (CIC). The SSC algorithm also enhances the training efficiency of downstream tasks for bipedal robots by 5% to 10%.</p>\n<p>Furthermore, I am actively exploring the potential of current unsupervised RL methods in the continual learning of dynamic environments. My work aims to push the boundaries of what is possible in autonomous driving, ensuring that RL algorithms can adapt and learn in ever-changing conditions, thus paving the way for more advanced and reliable autonomous systems.</p>\n<p>In addition, I have also participated in several engineering projects within the research team, such as real vehicle experiments.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/15/GPxHEaFwrKAd8oc.jpg\" alt=\"sim\" /></p>\n<p>In this project, my team built a large-scale simulation experiment platform, including a real vehicle simulation platform integrated with actual <span class=\"exturl\" data-url=\"aHR0cDovL2NvbmRpdGlvbnMuQXQ=\">conditions.At</span> the same time, our project places a strong emphasis on the development of fundamental algorithms for autonomous driving, which is the part I am responsible for.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/15/nlrY1O3fdHge2La.jpg\" alt=\"sim\" /></p>\n",
            "tags": [
                "Academic",
                "Engineer",
                "Tongji",
                "Tongji",
                "Engineer"
            ]
        },
        {
            "id": "http://yoursite.com/academic/research/tongji/ssc/",
            "url": "http://yoursite.com/academic/research/tongji/ssc/",
            "title": "Siamese Network-Driven Unsupervised RL",
            "date_published": "2023-12-01T01:00:00.000Z",
            "content_html": "<div class=\"note info\">\n<p><strong>title:</strong> A Lightweight Siamese Network-Driven Unsupervised Reinforcement Learning</p>\n</div>\n<div class=\"note info\">\n<p><strong>abstract:</strong> Unsupervised reinforcement learning(URL) has been a promising paradigm in recent years to design reinforcement learning (RL) agents that can be generalized to new tasks. Competence-based URLs are currently the most popular ones. However, two problems remain: In this paper, we introduce a Siamese Similarity Control (SSC) approach that uses Siamese networks for similarity estimation between state transfer and potential skills to learn effective behaviors. The proposed method is targeted at bipedal robots, and in comparison to other competence-based URL approaches, it exhibits an average improvement of approximately 30% in convergence speed across four tasks—standing, walking, running, and flipping. Additionally, it achieves a 5% to 10% increase in performance scores after 100k steps. Our experimental results are shown: <span class=\"exturl\" data-url=\"aHR0cHM6Ly9zaXRlcy5nb29nbGUuY29tL3ZpZXcvc2lhbWVzZS1zaW1pbGFyaXR5LWNvbnRyb2w=\">https://sites.google.com/view/siamese-similarity-control</span>.</p>\n</div>\n<h3 id=\"introduction\"><a class=\"anchor\" href=\"#introduction\">#</a> Introduction</h3>\n<p>I am the first author of the paper &quot;A Lightweight Siamese Network-Driven Unsupervised Reinforcement Learning.&quot; In this study, we explore the challenges of unsupervised reinforcement learning (URL) in complex environments, particularly focusing on bipedal robots. We introduce a Siamese Similarity Control (SSC) approach that leverages Siamese networks for similarity estimation between state transfer and potential skills to learn effective behaviors. Our method targets bipedal robots and shows significant improvements over existing competence-based URL methods in terms of convergence speed and performance.</p>\n<h3 id=\"background\"><a class=\"anchor\" href=\"#background\">#</a> Background</h3>\n<p>Unsupervised reinforcement learning (URL) has emerged as a powerful paradigm in robotics, enabling the rapid expansion of multiple downstream tasks through curiosity-driven strategies. Unlike traditional RL, URL does not rely on explicit reward signals to guide learning; instead, it uses self-supervised learning to generalize exploration information, facilitating experience transfer across tasks. Existing competence-based URL methods have demonstrated promising performance but often require complex structures to compensate for intrinsic motivation, and they lack targeted optimization for bipedal robots.</p>\n<p><img data-src=\"https://s2.loli.net/2024/02/02/HUKizj8yEW9nmbc.jpg\" alt=\"ssc\" /></p>\n<h3 id=\"proposed-method\"><a class=\"anchor\" href=\"#proposed-method\">#</a> Proposed Method</h3>\n<p>Our SSC method uses Siamese networks to estimate similarity between state transitions and potential skills. The key contributions of our method include:</p>\n<ol>\n<li><strong>Siamese Network Similarity Analysis</strong>: This provides an intuitive measure of mutual information, simplifying the driving method and enhancing the effectiveness of exploration.</li>\n<li><strong>Neural One-Hot Cross-Entropy (NOHC) Loss</strong>: This loss function, constructed using neural coding and one-hot encoding combined with cross-entropy, provides a more accurate representation of intrinsic motivation.</li>\n<li><strong>Shared Weight Networks</strong>: These networks simplify the algorithm's structure and update process, making it more efficient.</li>\n</ol>\n<h3 id=\"experimental-design\"><a class=\"anchor\" href=\"#experimental-design\">#</a> Experimental Design</h3>\n<p>We conducted experiments in various traffic flow conditions using a highway environment to simulate different traffic densities and lane configurations. The agent, a bipedal robot, was designed to perceive its surroundings and make decisions based on throttle depth and steering angle signals. Our approach was validated through four tasks: standing, walking, running, and flipping.</p>\n<h3 id=\"results-and-analysis\"><a class=\"anchor\" href=\"#results-and-analysis\">#</a> Results and Analysis</h3>\n<p>Our experimental results demonstrate that SSC significantly improves performance compared to baseline methods:</p>\n<ol>\n<li><strong>Performance Improvement</strong>: SSC achieves an average improvement of approximately 30% in convergence speed across the four tasks. It also shows a 5% to 10% increase in performance scores after 100k steps.</li>\n<li><strong>Algorithmic Efficiency</strong>: SSC requires fewer parameters and floating-point operations (FLOPs) compared to the CIC algorithm, demonstrating more efficient computation without compromising performance.</li>\n<li><strong>Superior Exploration and Skill Discovery</strong>: SSC effectively combines exploration and skill discovery, leading to more diverse and efficient skill acquisition.</li>\n</ol>\n<h3 id=\"conclusion\"><a class=\"anchor\" href=\"#conclusion\">#</a> Conclusion</h3>\n<p>This study presents a novel competence-based URL method that leverages Siamese networks for similarity estimation and NOHC loss for mutual information representation. Our SSC method effectively addresses the challenges of exploration and skill discovery in bipedal robots, showing significant improvements in both convergence speed and performance. Future work will extend this approach to other robotic domains and explore additional strategies to enhance the robustness and adaptability of RL agents in complex environments.</p>\n<p><img data-src=\"https://s2.loli.net/2024/02/02/XMgbP4Dd8qzC1Ku.jpg\" alt=\"ex\" /></p>\n<h3 id=\"future-work\"><a class=\"anchor\" href=\"#future-work\">#</a> Future Work</h3>\n<p>We plan to extend our SSC method to more complex and varied environments, such as urban traffic scenarios and other robotic tasks. Additionally, we aim to explore further optimizations to the NOHC loss function and the Siamese network architecture to improve the efficiency and effectiveness of our approach.</p>\n<p>This technical report summarizes our research, highlighting the key contributions and experimental findings, demonstrating the effectiveness of the SSC method in advancing unsupervised reinforcement learning for bipedal robots.</p>\n",
            "tags": [
                "Academic",
                "Research",
                "Tongji",
                "Research",
                "Tongji"
            ]
        },
        {
            "id": "http://yoursite.com/academic/research/tongji/url/",
            "url": "http://yoursite.com/academic/research/tongji/url/",
            "title": "Unsupervised Reinforcement Learning for Multi task Autonomous Driving",
            "date_published": "2023-08-01T01:00:00.000Z",
            "content_html": "<div class=\"note info\">\n<p><strong>title:</strong> Unsupervised Reinforcement Learning for Multi-task Autonomous Driving: Expanding Skills and Cultivating Curiosity</p>\n</div>\n<div class=\"note info\">\n<p><strong>abstract:</strong> In recent years, reinforcement learning (RL) has been widely used in decision-making. However, it still faces challenges when it is applied to autonomous driving, especially in complex multi-task scenarios. This paper introduces an unsupervised reinforcement learning(URL), called an improved Contrastive Intrinsic Control (CIC), to address this problem. CIC generates skills as transferable factors between different tasks to enable multi-task expansion. By comparing skills as potential state transfers with real state transfers, the mutual information between the two serves as the curiosity that drives the agents to explore the environment and gather experience in advance. This helps the collection of valuable experiences and the acquisition of effective skills. In the multi-task expansion phase, the unified training skills are used as a prior to enabling rapid convergence in various environments. Unified training is performed without rewards, followed by repeated training on multiple downstream tasks. Experiments are conducted in a highway environment, where three different driving modes are differentiated as separate RL tasks through reward functions. The experimental results demonstrate that the proposed method possesses the ability of multi-task learning. Compared to the Deep Deterministic Policy Gradient (DDPG) baseline, it achieves a 30% to 50% improvement in convergence speed at the single-task level and a 20% to 40% improvement in the final learning performance. Furthermore, even in complex tasks, where other RL methods struggle to learn effectively, it still achieves an obvious learning ability. This approach realizes an effective combination of curiosity mechanism, and RL decision making in the multitasking domain.</p>\n</div>\n<div class=\"note primary\">\n<p>This paper has been published in IEEE Transactions on <span class=\"exturl\" data-url=\"aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2Fic3RyYWN0L2RvY3VtZW50LzEwNTM4MjIx\">Intelligent Transportation Systems (IEEE T-ITS)</span>, and we welcome your citations!</p>\n</div>\n<h3 id=\"introduction\"><a class=\"anchor\" href=\"#introduction\">#</a> Introduction</h3>\n<p>As the first author of the paper &quot;Unsupervised Reinforcement Learning for Multi-task Autonomous Driving: Expanding Skills and Cultivating Curiosity,&quot; I am pleased to present a summary and technical report of our research. This study addresses the challenges of applying reinforcement learning (RL) to autonomous driving, especially in complex multi-task scenarios. We introduce an improved Contrastive Intrinsic Control (CIC) method to enhance skill transfer between different tasks, thereby enabling effective multi-task expansion and improving the performance of autonomous driving systems.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/14/HcuNCthM7kGboKg.jpg\" alt=\"cic\" /></p>\n<h3 id=\"background\"><a class=\"anchor\" href=\"#background\">#</a> Background</h3>\n<p>Reinforcement learning has been extensively used for decision-making in autonomous driving. However, traditional RL methods face significant challenges in multi-task environments due to their inability to differentiate common factors among tasks and to learn multiple tasks simultaneously. Existing approaches often require complex structures or compromise between different optimization criteria, making them less effective for practical autonomous driving applications.</p>\n<h3 id=\"proposed-method\"><a class=\"anchor\" href=\"#proposed-method\">#</a> Proposed Method</h3>\n<p>Our method leverages the improved CIC algorithm, which utilizes unsupervised reinforcement learning (URL) to generate transferable skills as meta-information between different tasks. By comparing potential state transfers (skills) with actual state transfers, the mutual information serves as a curiosity driver, encouraging the agent to explore the environment and gather valuable experience. This process helps in the acquisition of effective skills and enables rapid convergence in various environments.</p>\n<p>The key components of our method include:</p>\n<ol>\n<li><strong>Skill Generation and Transfer</strong>: Skills are generated as potential state transfers and used to drive the agent's exploration.</li>\n<li><strong>Mutual Information as Curiosity Driver</strong>: Mutual information between potential and actual state transfers is used to motivate the agent's exploration.</li>\n<li><strong>Unified Training for Multi-task Expansion</strong>: Skills are used as prior knowledge for multi-task expansion, allowing for rapid adaptation and convergence in different tasks.</li>\n</ol>\n<p><img data-src=\"https://s2.loli.net/2024/06/14/s9rLfBTU7ywjI8c.jpg\" alt=\"cic\" /></p>\n<h3 id=\"experimental-design\"><a class=\"anchor\" href=\"#experimental-design\">#</a> Experimental Design</h3>\n<p>We conducted experiments in a simulated highway environment, differentiating three driving modes (tasks) through reward functions: speed mode, energy-saving mode, and safety mode. These tasks were designed to represent distinct driving behaviors and objectives.</p>\n<h3 id=\"results-and-analysis\"><a class=\"anchor\" href=\"#results-and-analysis\">#</a> Results and Analysis</h3>\n<p>Our experimental results demonstrate the effectiveness of the improved CIC method in multi-task autonomous driving:</p>\n<ol>\n<li><strong>Convergence Speed</strong>: The CIC method achieved a 30% to 50% improvement in convergence speed compared to the Deep Deterministic Policy Gradient (DDPG) baseline at the single-task level.</li>\n<li><strong>Learning Performance</strong>: There was a 20% to 40% improvement in the final learning performance across different tasks.</li>\n<li><strong>Robustness in Complex Tasks</strong>: The CIC method showed a strong learning ability even in complex tasks where other RL methods struggled to learn effectively.</li>\n</ol>\n<h3 id=\"conclusion\"><a class=\"anchor\" href=\"#conclusion\">#</a> Conclusion</h3>\n<p>This study introduces a novel approach to unsupervised reinforcement learning for multi-task autonomous driving. By leveraging the improved CIC method, we achieve significant improvements in skill transfer, exploration efficiency, and overall learning performance. Our method effectively combines curiosity mechanisms with RL decision-making, making it well-suited for the dynamic and uncertain environments encountered in autonomous driving.</p>\n<h3 id=\"future-work\"><a class=\"anchor\" href=\"#future-work\">#</a> Future Work</h3>\n<p>Future research will focus on extending this approach to other domains and exploring additional strategies to enhance the robustness and adaptability of RL agents in complex environments. We aim to further improve the efficiency of skill generation and transfer processes, as well as to optimize the integration of curiosity-driven exploration with RL decision-making.</p>\n<p>This technical report provides an overview of our research, highlighting the key contributions and experimental findings, and demonstrates the potential of unsupervised reinforcement learning for advancing multi-task autonomous driving systems.</p>\n",
            "tags": [
                "Academic",
                "Research",
                "Tongji",
                "Research",
                "Tongji"
            ]
        },
        {
            "id": "http://yoursite.com/academic/engineer/tongji/nk/",
            "url": "http://yoursite.com/academic/engineer/tongji/nk/",
            "title": "Self-Evolving Learning-Based Autonomous Driving System",
            "date_published": "2023-04-08T01:00:00.000Z",
            "content_html": "<div class=\"note info\">\n<p><strong>project:</strong> Self-Evolving Learning-Based Autonomous Driving System.</p>\n</div>\n<div class=\"note info\">\n<h4 id=\"technical-objectives\"><a class=\"anchor\" href=\"#technical-objectives\">#</a> Technical Objectives</h4>\n<p>The project aims to address key challenges in the development of a self-evolving learning autonomous driving system, focusing on the critical scientific issue of ensuring safety and adaptability in complex, uncertain, and open environments. Our goal is to construct a comprehensive autonomous driving system encompassing fundamental theories, onboard computing devices, cloud-supported learning platforms, and integrated hardware and software development tools. We will also establish relevant national/industry standards to accelerate the development and large-scale application of autonomous driving technology.</p>\n<h4 id=\"research-plan\"><a class=\"anchor\" href=\"#research-plan\">#</a> Research Plan</h4>\n<ol>\n<li><strong>Fundamental Theory Research</strong>:\n<ul>\n<li><strong>Understanding Open Driving Scenarios and Iterative Learning for Autonomous Decision-Making</strong>: Investigate long-term behavior prediction techniques for traffic participants and develop general modeling, optimization, and analysis software to enhance the system's understanding and decision-making capabilities in dynamic environments.</li>\n<li><strong>Safe Self-Learning Planning Control and Efficient Parallel Computing</strong>: Develop efficient parallel computing techniques to accelerate the solution of planning and control algorithms, ensuring the safety and robustness of the autonomous driving system under high real-time requirements.</li>\n</ul>\n</li>\n<li><strong>Hardware and Software System Development</strong>:\n<ul>\n<li><strong>Real-Time Onboard Computing Device with Hardware-Software Co-Optimization</strong>: Design and develop a real-time onboard computing device that meets the demands of autonomous driving, optimizing the co-design of hardware and software to achieve efficient computing capabilities.</li>\n<li><strong>Cloud-Supported Virtual-Real Hybrid Closed-Loop Learning and Performance Evaluation</strong>: Build a cloud-based hybrid learning platform using personalized federated learning and multi-task learning techniques to enhance the self-evolution capabilities and performance evaluation efficiency of the autonomous driving system.</li>\n</ul>\n</li>\n<li><strong>Real Vehicle Validation and Integration</strong>:\n<ul>\n<li><strong>Integration and Real Vehicle Validation of the Learning Autonomous Driving System</strong>: Conduct real-world road tests and validations through rigorous testing processes to ensure system reliability and safety. Additionally, employ database obfuscation and multi-key homomorphic encryption techniques to establish a multi-vehicle cooperative evolution model supporting personalized learning.</li>\n</ul>\n</li>\n</ol>\n<p>Through the implementation of this research plan, we aim to achieve breakthroughs in self-evolving learning autonomous driving systems, promoting the industrial application of autonomous driving technology and enhancing China's international competitiveness in this field.</p>\n</div>\n<div class=\"note primary\">\n<ul>\n<li><strong>Student leader</strong> of the sub-project &quot;Mixed Real Vehicle Validation of Learning-Based Autonomous Driving Systems&quot; within the National Key R&amp;D Program &quot;Self-Evolving Learning-Based Autonomous Driving System.&quot;</li>\n<li>In this project, my team includes members from Tsinghua University, Tongji University, Dongfeng Motor Corporation.</li>\n</ul>\n</div>\n<p><strong>Self-Evolving Learning-Based Autonomous Driving System | Tongji University | Directed by Prof. Yanjun Huang | (No2022YFB2502900) | Supported by National Key Research and Development Program (the highest level of R&amp;D programme in China).</strong></p>\n<p>I have developed an improved unsupervised reinforcement learning (RL) framework specifically for autonomous driving. This framework has led to significant improvements in decision-making capabilities and learning speed, achieving enhancements of approximately 30% and 40%, respectively. My work in this area has been pivotal in advancing the efficiency and effectiveness of autonomous driving systems.</p>\n<p>Additionally, I have focused on multi-vehicle cooperative evolution, leading a major project within the national key R&amp;D program. This project aims to foster collaborative learning and evolution among multiple autonomous vehicles, enhancing their collective intelligence and adaptability in complex environments.</p>\n<p>Furthermore, I am actively participating in the construction of a mixed reality simulation test platform. This platform combines vehicle hardware-in-the-loop (HIL) with virtual traffic scenarios to create a comprehensive testing environment. This initiative is crucial for validating and refining autonomous driving algorithms under realistic and varied conditions. Currently, I am also involved in developing a general simulation software to support these testing efforts and ensure robust performance evaluation.</p>\n<p>Moreover, I am contributing to the design of a generalized autonomous driving observation encoder. This encoder is capable of utilizing LiDAR observation information to significantly improve the decision-making processes in reinforcement learning. By integrating advanced sensory data, this encoder enhances the system's perception and situational awareness, leading to more accurate and reliable autonomous driving decisions.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/15/AhyY2s78qmdiGTZ.png\" alt=\"sim\" /></p>\n<p>In addition to these initiatives, my team and I have developed a comprehensive large-scale mixed reality experimental platform. We have replicated one of China's most advanced real vehicle testing grounds on a simulation platform based on Carla. This includes rich cloud control equipment and various types of autonomous vehicles. We have developed numerous APIs to facilitate vehicle-end control, cloud control, and joint control. This platform is currently the most advanced autonomous driving simulation test platform in China, and we have commercialized the entire system into a comprehensive software suite. Our work has gained recognition from industry experts both domestically and internationally.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/15/JoaKvZzXTBdnUNP.jpg\" alt=\"sim\" /></p>\n<p>Currently, within this massive project, I am leading one of the sub-projects, focusing on multi-vehicle coordination development. While my previous research primarily concentrated on foundational algorithms for autonomous driving, since taking on this sub-project in March 2024, my team and I have been focusing on agent reasoning, knowledge reuse, and transfer learning.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/15/xKiPDwetgBM2JuC.jpg\" alt=\"sim\" /></p>\n<p><img data-src=\"https://s2.loli.net/2024/06/15/GPxHEaFwrKAd8oc.jpg\" alt=\"sim\" /></p>\n",
            "tags": [
                "Academic",
                "Engineer",
                "Tongji",
                "Tongji",
                "Engineer"
            ]
        },
        {
            "id": "http://yoursite.com/academic/research/jlu/machine/",
            "url": "http://yoursite.com/academic/research/jlu/machine/",
            "title": "Mechanical Design at JLU Racing, Jilin University.",
            "date_published": "2020-08-01T01:00:00.000Z",
            "content_html": "<p>In JLU Racing at Jilin University, my research primarily focused on the design of gears and the transmission system of racing cars. Below are the main contents of my papers and patents:</p>\n<p>The title of the paper is &quot;Research on the Characteristics of Rubber Belt Type CVT in Baja Racing Car.&quot; The main research content includes:</p>\n<ol>\n<li><strong>Background and Objective</strong>: The rubber belt type CVT (Continuously Variable Transmission) is simple, reliable, and smooth in transmission, making it suitable for Baja racing cars. The study aims to improve the transmission efficiency of the CVT and better match the engine's power with the overall vehicle performance.</li>\n<li><strong>Experimental Methods</strong>:\n<ul>\n<li><strong>Engine Bench Test</strong>: Measuring the power and torque of the Briggs &amp; Stratton M19 engine at different speeds to plot the engine's external characteristic curves.</li>\n<li><strong>CVT Bench Test</strong>: Measuring the speed and torque of the CVT to plot its external characteristic curves and analyze its efficiency at different temperatures.</li>\n</ul>\n</li>\n<li><strong>Experimental Results</strong>:\n<ul>\n<li><strong>Temperature Impact on CVT Efficiency</strong>: Temperature is the main factor affecting CVT efficiency, with the highest efficiency at 55℃.</li>\n<li><strong>Effect of Flyweights and Springs on CVT</strong>: Choosing a combination of light flyweights and heavy springs allows the Baja car to have greater driving force during startup and quickly reach the highest theoretical speed.</li>\n<li><strong>Selection of Gear Reducer Transmission Ratio</strong>: Determining the total transmission ratio of the reducer to be 12.9, which enables the vehicle to achieve a maximum speed of 60 km/h, enhancing the vehicle's power performance.</li>\n</ul>\n</li>\n<li><strong>Conclusion</strong>:\n<ul>\n<li>Maintaining the CVT within an appropriate temperature range (e.g., 55℃) ensures high efficiency.</li>\n<li>By optimizing the combination of flyweights and springs and reasonably designing the transmission ratio of the gear reducer, the power performance and maximum speed of the Baja racing car can be significantly improved.</li>\n</ul>\n</li>\n</ol>\n<p>This paper uses experimental data and analysis to propose methods to improve the transmission efficiency of rubber belt type CVTs, providing a scientific basis for optimizing the power performance of Baja racing cars.</p>\n<p><strong>Patent: An All-Terrain Vehicle Full-Time Four-Wheel Drive System for Small and Medium-Sized Vehicles</strong></p>\n<p>The present invention relates to the field of vehicle technology, specifically an all-terrain vehicle full-time four-wheel drive system for small and medium-sized vehicles, which includes a main reducer, a CVT (Continuously Variable Transmission), and a front differential. The main reducer is connected to the engine through a vibration damping component. The input end of the main reducer is connected to the engine via the CVT. One output end of the main reducer is connected to the front differential through a drive shaft. The front differential is connected to the front wheels through half shafts, and the other output end is connected to the rear wheels through half shafts. Protective devices are installed at the connection points between the drive shaft and the main reducer, the front differential, or on the CVT, to protect the drive shaft, the CVT, the main reducer, and the front differential. The main reducer integrates an inter-axle differential and a rear axle differential, which are engaged and connected through a bevel gear set.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/15/MIDNl2FExhkHqA1.png\" alt=\"url\" /></p>\n<p><strong>Advantages of the Invention</strong>: The integration of the three types of differentials within a relatively small effective space allows for power distribution while ensuring steering performance. This system provides better passing ability and steering performance.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/04/6MCvlG5qbAEfKLz.jpg\" alt=\"url\" /></p>\n<p><strong>Patent: A Specialized Main Reducer for Full-Time Four-Wheel Drive Small and Medium-Sized All-Terrain Vehicles</strong></p>\n<p>The present invention relates to the field of reducer technology, specifically a specialized main reducer for full-time four-wheel drive small and medium-sized all-terrain vehicles, comprising:</p>\n<ul>\n<li><strong>Housing</strong>: The housing features an inner cavity designed for installing the transmission structure.</li>\n<li><strong>Transmission Structure</strong>: This includes a power input end, a centrally positioned differential assembly, and a rear axle differential assembly, which are meshed and connected. One end of the central differential assembly, which is far from the rear axle differential assembly, is transmission-connected to the front axle. The side of the central differential assembly is engaged with the power input end. Both sides of the rear axle differential assembly are transmission-connected to the two sides of the rear axle.</li>\n<li><strong>Cleaning Mechanism</strong>: Positioned on the housing, the cleaning mechanism is used to purify the working environment of the transmission structure within the inner cavity and adjust the pressure difference between the inner cavity and the external environment.</li>\n</ul>\n<p><img data-src=\"https://s2.loli.net/2024/06/15/pnkZtfwGTMu1oaN.png\" alt=\"url\" /></p>\n<p><strong>Advantages of the Invention</strong>: The transmission structure includes a power input end, a centrally positioned differential assembly, and a rear axle differential assembly, which are meshed and connected. This design provides a differential effect between the front axle and the two sides of the rear axle wheels, improving the turning radius and the four-wheel drive's passing capability.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/04/sNGwFU3BbfDSalT.jpg\" alt=\"url\" /></p>\n<p><strong>Patent: A Shifting Mechanism and Reducer for Baja Racing Cars</strong></p>\n<p>The present invention relates to the field of vehicle technology, specifically to a shifting mechanism and reducer for Baja racing cars. The shifting mechanism for the Baja racing car includes an intermediate shaft and an input end. The intermediate shaft has gear wheels installed at both ends, and switching components are installed between the gear wheels. The switching components consist of a shift fork and an engagement sleeve mounted on the intermediate shaft. The shift fork controls the engagement sleeve to move towards and engage with one gear wheel, thereby connecting this gear wheel to the input end, or it controls the engagement sleeve to move towards and engage with the other gear wheel, thus connecting the other gear wheel to the input end.</p>\n<p><strong>Advantages of the Invention</strong>: The invention achieves variable transmission ratio power output with a simple, safe, and reliable structure. It is suitable for the transmission of Baja racing cars and can better adapt to the complex road conditions encountered during races, providing higher safety, stability, and operability in actual competition scenarios.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/15/GmD9ybWketo3I5J.png\" alt=\"url\" /></p>\n<p><strong>Patent: A Four-Wheel Drive Reducer Housing and Reducer for Baja Racing Cars</strong></p>\n<p>The present invention relates to the field of mechanical technology, specifically to a four-wheel drive reducer housing and reducer for Baja racing cars. The four-wheel drive reducer housing for Baja racing cars is used to enclose the transmission components and fix them onto the vehicle frame. It includes a housing body with input end mounting sections and output end mounting sections on both sides. The housing body, on the same side as the output end mounting sections, is equipped with one or more intermediate output mounting sections.</p>\n<p>The reducer comprises the transmission components and the aforementioned four-wheel drive reducer housing for Baja racing cars. The transmission components are installed within the four-wheel drive reducer housing.</p>\n<p><strong>Advantages of the Invention</strong>: The invention provides multiple power outputs, ensuring the performance and reliability of the four-wheel drive Baja racing car that uses the four-wheel drive reducer housing. Additionally, it features a stable structure.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/15/Inj1VCfs2HFgGZv.png\" alt=\"url\" /></p>\n",
            "tags": [
                "Academic",
                "Research",
                "JLU",
                "Research",
                "JLU"
            ]
        },
        {
            "id": "http://yoursite.com/academic/engineer/jlu/machine/",
            "url": "http://yoursite.com/academic/engineer/jlu/machine/",
            "title": "I, and JLU Racing, Jilin University.",
            "date_published": "2020-08-01T01:00:00.000Z",
            "content_html": "<p>I was responsible for the design of the BAJA racing car at JLU Racing, Jilin University, with a primary focus on the vehicle's transmission system.</p>\n<p>I joined JLU Racing in 2018 and participated as a regular team member in the 2018-2019 season, completing the race in Changbai Mountain in August 2019.</p>\n<p>In the second half of 2019, due to changes in the competition rules following the American BAJA competition, the Chinese BAJA competition lifted the restrictions on four-wheel-drive transmission systems. Starting in 2019, I took charge of designing a part-time four-wheel-drive transmission system. With the onset of the COVID-19 pandemic in 2020, I assumed the role of head of the transmission system at JLU Racing. In the first half of that year, we launched China's first part-time four-wheel-drive small all-terrain vehicle.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/04/3oLpPWTADnzXO1M.jpg\" alt=\"url\" /></p>\n<p>However, due to the COVID-19 pandemic, we were unable to participate in the 2019-2020 season. Over the following three years, China's strict lockdown policies prevented us from participating in the world collegiate BAJA competition held in the United States. Despite invitations to international competitions from countries such as Russia, neither my team nor I could participate.</p>\n<p>&lt;iframe src=&quot;<a href=\"//player.bilibili.com/player.html?isOutside=true&amp;aid=510364930&amp;bvid=BV1mu411i752&amp;cid=566134912&amp;p=1\">//player.bilibili.com/player.html?isOutside=true&amp;aid=510364930&amp;bvid=BV1mu411i752&amp;cid=566134912&amp;p=1</a>&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;</p>\n<p>In the 2020-2021 season, I became the captain and technical director of JLU Racing. During this time, my team and I designed China's first full-time four-wheel-drive small all-terrain vehicle, and we won the design championship in the Chinese BAJA competition.</p>\n<p>&lt;iframe src=&quot;<a href=\"//player.bilibili.com/player.html?isOutside=true&amp;aid=769373602&amp;bvid=BV1Gr4y1t7Xi&amp;cid=728509696&amp;p=1\">//player.bilibili.com/player.html?isOutside=true&amp;aid=769373602&amp;bvid=BV1Gr4y1t7Xi&amp;cid=728509696&amp;p=1</a>&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;</p>\n<p>From 2020 to 2021, I was responsible for the team's technical design work, primarily focusing on the transmission system design, with a particular expertise in gear systems. During this period, I was invited by Jilin University to teach a course on &quot;CATIA&quot; via the university's online platform. Additionally, I was invited by the domestic mechanical simulation company, 仿真秀，to lecture on &quot;ROMAX,&quot; and I was also invited to teach mechanical design at Changchun Automobile College.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/04/wkKtl8RGOTFjCL9.jpg\" alt=\"url\" /></p>\n<p>During this time, I published two papers in domestic journals in China and filed eight patents.</p>\n<p>In the 2021-2022 season, my team and I once again won the design championship in the Chinese BAJA competition.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/04/9VeSmr7JInbtUPK.jpg\" alt=\"url\" /></p>\n<p>For the 2022-2023 season, while I was at Tongji University, I received an invitation to serve as the chief judge for the Chinese BAJA competition.</p>\n<p><img data-src=\"https://s2.loli.net/2024/06/04/HxXgLOVCTuQb31P.jpg\" alt=\"url\" /></p>\n<p>Over my four years at JLU Racing, I developed strong engineering skills, including proficiency in CATIA, CAD, and familiarity with ROMAX, SOFTMAX, and ANSYS software. I am also skilled in operating lathes, metalworking, and welding. In the design of gear and other transmission system components, I was responsible for the entire process from design to manufacturing.</p>\n<p>&lt;iframe src=&quot;<a href=\"//player.bilibili.com/player.html?isOutside=true&amp;aid=213344074&amp;bvid=BV1ia411v7cy&amp;cid=580282474&amp;p=1\">//player.bilibili.com/player.html?isOutside=true&amp;aid=213344074&amp;bvid=BV1ia411v7cy&amp;cid=580282474&amp;p=1</a>&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;</p>\n",
            "tags": [
                "Academic",
                "Engineer",
                "JLU",
                "JLU",
                "Engineer"
            ]
        }
    ]
}